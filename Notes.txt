* Understand top_p concept
    Top_p changes how the model selects tokens for output. Tokens are selected from the most to least probable until
    the sum of their probabilities equals the top_p value. For example, if tokens A, B and C have probability of 0.3,
    0.2, and 0.1 and the top_p value is 0.5, then the model will select either A or B as the next token by using
    temperature and excludes C as a candidate.

* Understand top_k concept
    top_k changes how the model selects tokens for output. A top_k of 1 means the next selected token is the most
    probable among all tokens in the model's vocabulary (also called greedy decoding), while a top_k of 3 means that the
    next token is selected from among the three most probable tokens by using temperature.
